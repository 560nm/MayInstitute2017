---
title: 'Day 2: Beginner''s statistics in R'
author: "Laurent Gatto, Meena Choi and Data Carpentry"
output: 
  html_document:
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Objectives

- Reading data in R
- Data manipulation and exploration
- Data distributions
- Select random sample and randomize MS run orders
- Visualisation
- Hypothesis testing: t-test 

---

Parts of the `data.frame` material is based on the
[R for data analysis and visualization](http://www.datacarpentry.org/R-ecology-lesson/index.html)
Data Carpentry course.

# Reading in data

The file we'll be reading in is a dataset that has been 1) processed
in Skyline and 2) summarized by each run and protein with
`MSstats`. We will practice with it.

**Tip** Often you'll get data delivered as a Microsoft Excel file. You
can export any spreadsheet to a `.csv` (comma separated values) file
in Excel through the `Save As.. > Format: Comma Separated Values
(.csv)` menu item.

In Rstudio, go to the `environnment` pane, click on `Import Dataset`
dropdown and choose `From Text File...` from the dropdown menu. Import
the `iPRG_example_runsummary.csv` file from your data directory, and
inspect that Rstudio correctly parsed the text file into an R
`data.frame`.


Now inspect the `Console` `Environment` pane again. Notice that a new
variable for the `iPRG_example` data frame was created in the
environment by executing the `read.csv` function. Let's have a look at
the documentation for this function by pulling up the help pages with
the `?`.

```{r}
iprg <- read.csv("./data/iPRG_example_runsummary.csv")
```

# Data frames

## Tidy data

The `iprg` object that we created is a `data.frame`

```{r}
class(iprg)
```

These object are the equivalent of a sheet in a spreadsheet file. They
are composed on a set of columns, which are different vectors (or
characters, numerics, factors, ...) as seen prevously. 

There are actually some additional contstrains compared to a
spreadsheet. Rather than being limitations, these constrains are an
important feature that allow some standardisation and hence automatic
computations.

* All the data in a `data.frame` must be included in a column, as a
  vector. This means that it's not possible to add *random* notes or
  values, as is sometimes seen in spreadsheets. 
  
* All columns/vectors must have the same length, as opposed to
  spreadsheets, where sometimes some values or summary statistics are
  added at the bottom.
  
* No colours or font decorations.

This leads us to a very important concept in data formatting and data
manipuation, which is that data should be *tidy*, where 

* Columns describe different variables
* Rows describe different observations
* A cell contains a measurement or piece of information for a single
  observation.

There are two important reasons that we want tidy data

1. No need to tidy it up, which is a task many of us waste way to much
   time with.
2. The data is well structured, easy to read in, whatever the software
   or programming languages, and is easy to reason about.


Note that data is alwasy tidy, and for good reasons so. For example,
omics data is often presented as shown below

```{r, echo=FALSE, cache=TRUE, message=FALSE}
library("pRolocdata")
data(mulvey2015)
knitr::kable(exprs(mulvey2015)[1:5, 1:5])
```

which is not stictly tidy, as the protein intensity is presented along
muliple columns. 

> ### Challenge
> 
> Compare the structure of the data presented above and the `iprg`
> data.

## What are data frames?

Data frames are the _de facto_ data structure for most tabular data, and what we
use for statistics and plotting.

A data frame can be created by hand, but most commonly they are generated by the
functions `read.csv()` or `read.table()`; in other words, when importing
spreadsheets from your hard drive (or the web).

A data frame is the representation of data in the format of a table where the
columns are vectors that all have the same length. Because the column are
vectors, they all contain the same type of data (e.g., characters, integers,
factors). We can see this when inspecting the <b>str</b>ucture of a data frame
with the function `str()`:

```{r}
str(iprg)
```

## Inspecting `data.frame` Objects

We already saw how the functions `head()` and `str()` can be useful to check the
content and the structure of a data frame. Here is a non-exhaustive list of
functions to get a sense of the content/structure of the data. Let's try them out!

* Size:
    * `dim(iprg)` - returns a vector with the number of rows in the first element,
          and the number of columns as the second element (the **dim**ensions of
          the object)
    * `nrow(iprg)` - returns the number of rows
    * `ncol(iprg)` - returns the number of columns

* Content:
    * `head(iprg)` - shows the first 6 rows
    * `tail(iprg)` - shows the last 6 rows

* Names:
    * `names(iprg)` - returns the column names (synonym of `colnames()` for `data.frame`
	   objects)
    * `rownames(iprg)` - returns the row names

* Summary:
    * `str(iprg)` - structure of the object and information about the class, length and
	   content of  each column
    * `summary(iprg)` - summary statistics for each column

Note: most of these functions are "generic", they can be used on other types of
objects besides `data.frame`.


> ### Challenge
>
> Based on the output of `str(iprg)`, can you answer the following questions?
>
> * What is the class of the object `iprg`?
> * How many rows and how many columns are in this object?
> * How many proteins have been assayed?

## Indexing and subsetting data frames

Our data frame has rows and columns (it has 2 dimensions), if we want
to extract some specific data from it, we need to specify the
*coordinates* we want from it. Row numbers come first, followed by
column numbers. However, note that different ways of specifying these
coordinates lead to results with different classes.

```{r, eval=FALSE}
iprg[1]      # first column in the data frame (as a data.frame)
iprg[, 1]    # first column in the data frame (as a vector)
iprg[1, 1]   # first element in the first column of the data frame (as a vector)
iprg[1, 6]   # first element in the 6th column (as a vector)
iprg[1:3, 3] # first three elements in the 3rd column (as a vector)
iprg[3, ]    # the 3rd element for all columns (as a data.frame)
head_iprg <- iprg[1:6, ] # equivalent to head(iprg)
```

`:` is a special function that creates numeric vectors of integers in
increasing or decreasing order, test `1:10` and `10:1` for instance.

You can also exclude certain parts of a data frame using the `-` sign:

```{r, eval=FALSE}
iprg[, -1]          # The whole data frame, except the first column
iprg[-c(7:36321), ] # Equivalent to head(iprg)
```

As well as using numeric values to subset a `data.frame` columns can
be called by name, using one of the four following notations:

```{r, eval = FALSE, purl=FALSE}
iprg["Protein"]       # Result is a data.frame
iprg[, "Protein"]     # Result is a vector
iprg[["Protein"]]     # Result is a vector
iprg$Protein          # Result is a vector
```

For our purposes, the last three notations are equivalent. RStudio
knows about the columns in your data frame, so you can take advantage
of the autocompletion feature to get the full and correct column name.

> ### Challenge
>
> 1. Create a `data.frame` (`oprg_200`) containing only the observations from
>    row 200 of the `iprg` dataset.
>
> 2. Notice how `nrow()` gave you the number of rows in a `data.frame`?
>
>      * Use that number to pull out just that last row in the data frame.
>      * Compare that with what you see as the last row using `tail()` to make
>        sure it's meeting expectations.
>      * Pull out that last row using `nrow()` instead of the row number.
>      * Create a new data frame object (`iprg_last`) from that last row.
>
> 3. Use `nrow()` to extract the row that is in the middle of the data
>    frame. Store the content of this row in an object named `iprg_middle`.
>
> 4. Combine `nrow()` with the `-` notation above to reproduce the behavior of
>    `head(iprg)` keeping just the first through 6th rows of the iprg
>    dataset.


# Factors

```{r, echo=FALSE, purl=TRUE}
### Factors
```

When we did `str(iprg)` we saw that several of the columns consist of
numerics, however, the columns `Protein`, `Run`, and `Condition`, are
of a special class called a `factor`. Factors are very useful and are
actually something that make R particularly well suited to working
with data, so we're going to spend a little time introducing them.

Factors are used to represent categorical data. Factors can be ordered
or unordered, and understanding them is necessary for statistical
analysis and for plotting.

Factors are stored as integers, and have labels (text) associated with
these unique integers. While factors look (and often behave) like
character vectors, they are actually integers under the hood, and you
need to be careful when treating them like strings.

Once created, factors can only contain a pre-defined set of values,
known as *levels*. By default, R always sorts *levels* in alphabetical
order. For instance, if you have a factor with 2 levels:

```{r}
sex <- factor(c("male", "female", "female", "male"))
```

R will assign `1` to the level `"female"` and `2` to the level
`"male"` (because `f` comes before `m`, even though the first element
in this vector is `"male"`). You can check this by using the function
`levels()`, and check the number of levels using `nlevels()`:


```{r}
levels(sex)
nlevels(sex)
```

Sometimes, the order of the factors does not matter, other times you
might want to specify the order because it is meaningful (e.g., "low",
"medium", "high"), it improves your visualization, or it is required
by a particular type of analysis. Here, one way to reorder our levels
in the `sex` vector would be:

```{r, results=TRUE, purl=FALSE}
sex # current order
sex <- factor(sex, levels = c("male", "female"))
sex # after re-ordering
```

In R's memory, these factors are represented by integers (1, 2, 3),
but are more informative than integers because factors are self
describing: `"female"`, `"male"` is more descriptive than `1`,
`2`. Which one is "male"?  You wouldn't be able to tell just from the
integer data. Factors, on the other hand, have this information built
in. It is particularly helpful when there are many levels (like the
species names in our example dataset).

### Converting factors

If you need to convert a factor to a character vector, you use
`as.character(x)`.

```{r}
as.character(sex)
```

### Using `stringsAsFactors=FALSE`

By default, when building or importing a data frame, the columns that
contain characters (i.e., text) are coerced (=converted) into the
`factor` data type. Depending on what you want to do with the data,
you may want to keep these columns as `character`. To do so,
`read.csv()` and `read.table()` have an argument called
`stringsAsFactors` which can be set to `FALSE`.

In most cases, it's preferable to set `stringsAsFactors = FALSE` when
importing your data, and converting as a factor only the columns that
require this data type.

> Challenge
> 
> Compare the output of `str(surveys)` when setting `stringsAsFactors = TRUE` (default) and `stringsAsFactors = FALSE`:
```{r, eval=FALSE, purl=FALSE}
iprg <- read.csv("data/iPRG_example_runsummary.csv", stringsAsFactors = TRUE)
str(iprg)
iprg <- read.csv("data/iPRG_example_runsummary.csv", stringsAsFactors = FALSE)
str(iprg)
```

# Other data structures

|          | dimensions | number of types | 
|:---------|------------|-----------------|
| vectors  |       1    |       1         | 
| matrix   |       2    |       1         | 
| array    |     any    |       1         | 
|data.frame|       2    | 1 per colums    | 
| list     | 1 (length) | any             |



# Data exploration

Let's explore some basic properties of our dataset. Go to the RStudio
Environment pane and double click the `iPRG_example` entry. This data
is in tidy,*long* format, which is an easier data format for data
manipulation operations such as selecting, grouping, summarizing, etc.


![Example data for this section](iprgexample.png)

Data exported out of many omics processing or quantification tools are
often formatted in *wide* format, which is easier to read when we
would like to compare values (i.e intensity values) for specific
subjects (i.e peptides) across different values for a variable of
interest such as (i.e conditions). We'll format a summary of this
dataset as a 'wide' data frame later in this tutorial.

Let's do some more data exploration by examining how R read in the
iPRG dataset.


> ### Challenge: 
> 
> Explore the data as described below
>
> * What is the *class* of the variable?
> * What dimension is it? How many rows and columns does it have?
> * What variables (column names) do we have?
> * Look at the few first and last lines to make sure the data was
>   imported correctly.
> * Display a summary of the whole data.



Inspect the possible values for the `Conditions` and the `BioReplicate` (8th) column using the named and numbered column selection syntax for data frames.

```{r,echo=T,eval=T}
unique(iprg[, 'Condition'])
unique(iprg[, 4])

unique(iprg[, c('Condition', 'BioReplicate', 'Run')])
```

Select subsets of rows from iPRG dataset: i.e we might be interested in working from here on only with Condition1 or all measurements on one particular MS run.

```{r, eval=T}
# subset of data for condition1
iprg.condition1 <- iprg[iprg$Condition == 'Condition1', ]
iprg.condition1.bio1 <- iprg[iprg$Condition == 'Condition1' 
                               & iprg$BioReplicate == '1', ]
nrow(iprg.condition1.bio1)
```

```{r, eval=T}
# subset of data for condition1 or condition2
iprg.condition1.2 <- iprg[iprg$Condition == 'Condition1' 
                          | iprg$Condition == 'Condition2', ]
nrow(iprg.condition1.2)
unique(iprg.condition1.2$Condition)
```
```{r, eval=T}
# subset of data for condition1 or condition2
iprg.condition1.2 <- iprg[which(iprg$Condition %in% c('Condition1', 'Condition2')), ]
nrow(iprg.condition1.2)
unique(iprg.condition1.2$Condition)
```


***
# 4. Summarizing and Visualizing data

## 4.1 Histogram

Make a histogram of all the MS1 intensities, quantified by Skyline, for `iPRG_example`.

```{r,eval=T,echo=T, fig.width=5, fig.height=4}
hist(iprg$Intensity)
```

Our histogram looks quite skewed. How does this look on log-scale? Do you recognize this distribution? The distribution for log2-transformed intensities looks very similar to the normal distribution. The advantage of working with normally distributed data is that we can apply a variety of statistical tests to analyzeand interpret our data. Let's add a log2-scaled intensity column to our data so we don't have to transform the original intensities every time we need them.  

```{r,eval=T,echo=T, fig.width=5, fig.height=4}
hist(iprg$Log2Intensity, 
     xlab="log2 transformed intensities", main="Histogram of iPRG data")
```

```{r,eeval=T,echo=T, fig.width=5, fig.height=4}
# or directly transform the intensities.
hist(log2(iprg$Intensity), 
     xlab="log2 transformed intensities", main="Histogram of iPRG data")
```

We look at the summary for the log2-transformed values including the value for the mean. Let's fix that first. 

```{r,eval=T}
summary(iprg$Log2Intensity)
```


***
## 4.2 Boxplot or box-and-whisker plot

Boxplots are extremely useful becasue they allow us to quickly visualize the data distribution, without making assumptions of the distribution type (non-parametric). We can read up on what statistics the different elements of a box-and-whisker represent in the R help files.   

Let's make the boxplot with `ggplot2`, one of the most popular and powerful R packages for making graphics. The syntax of ggplot2 might seem a bit intimidating at first, but besides the advantage of having full control over all graphical elements of your plot, two other advantages are that 1) it's very straightforward to automatically assign distinguishing graphical elements to subsets of your data and 2) switching between plot types requires little changes to your code. Let's start with a bare bones boxplot.  

```{r,eval=T, warning=F}
library(ggplot2)
ggplot(aes_string(x='Run', y='Log2Intensity'), data=iprg)+
    			geom_boxplot(aes_string(fill='Condition'))

```

Now let's rename all axis labels and title, and rotate the x-axis labels 90 degrees. We can add those specifications using the `labs` and `theme` functions of the `ggplot2` package.

```{r,eval=T, warning=F}
ggplot(aes_string(x='Run', y='Log2Intensity'), data=iprg)+
      		geom_boxplot(aes_string(fill='Condition'))+
          labs(title='Log2 transformed intensity distribution per MS run', 
               y='Log2(Intensity)',
               x='MS run')+
          theme(axis.text.x=element_text(angle=90))
    
```


And easily switch from a boxplot to a violin plot representation by changing the `geom` type. 

```{r,eval=T, warning=F}
ggplot(aes_string(x='Run', y='Log2Intensity'), data=iprg)+
        	geom_violin(aes_string(fill='Condition'))+
          labs(title='Log2 transformed intensity distribution per Subject', 
               y='Log2(Intensity)',
               x='MS run')+
          theme(axis.text.x=element_text(angle=90))
```


***
# 5. Randomization

## 5.1 Random selection of samples from a larger set

This particular dataset contains a total of 10 subjects across conditions. Suppose we label them from 1 to 14 and randomly would like to select 3 subjects we can do this using the `sample` function. When we run `sample` another time, different subjects will be selected. Try this a couple times.

```{r}
sample(10, 3)
sample(10, 3)
```

Now suppose we would like to select the same randomly selected samples every time, then we can use a random seed number.

```{r}
set.seed(3728)
sample(10, 3)

set.seed(3728)
sample(10, 3)
```

## 5.2 Completely randomized order of MS runs 

We can also create a random order using all elements of iPRG dataset. Again, we can achieve this using `sample`, asking for exactly the amount of samples in the subset. This time, each repetition gives us a different order of the complete set.

```{r}
msrun <- unique(iprg$Run)
msrun

# randomize order among all 12 MS runs
sample(msrun, length(msrun))

# different order will be shown.
sample(msrun, length(msrun))
```

## 5.3 Randomized block design

- Allow to remove known sources of variability that you are not interested in.

- Group conditions into blocks such that the conditions in a block are as similar as possible.

- Randomly assign samples with a block.

This particular dataset contains a total of 12 MS runs across 4 conditions, 3 technical replicates per condition. Using the `block.random` function in the `psych` package, we can achieve randomized block designs!

```{r}
# use 'psych' package
library(psych)

msrun <- unique(iprg[, c('Condition','Run')])
msrun

# 4 Conditions of 12 MS runs randomly ordered
block.random(n=12, c(Condition=4))
```

# 6. Saving your work 

You can save plots to a number of different file formats. PDF is by far the most common format because it's lightweight, cross-platform and scales up well but jpegs, pngs and a number of other file formats are also supported. Let's redo the last barplot but save it to the file system this time. 

Let's save the boxplot as pdf file.
```{r,eval=T, warning=F}
pdf('boxplot_log2intensity_distribution_byMSrun.pdf', width=10, height=8)
ggplot(aes_string(x='Run', y='Log2Intensity'), data=iprg)+
      		geom_boxplot(aes_string(fill='Condition'))+
          labs(title='Log2 transformed intensity distribution per MS run', 
               y='Log2(Intensity)',
               x='MS run')+
          theme(axis.text.x=element_text(angle=90))
dev.off() 
```

Finally, we can save this whole session you worked so hard on! 

```{r,eval=T}
save.image(file='Section1.RData')
```

Ok let's give it a rest now. Saving an .RData is the easiest way to pick up your work right where you left it!

```{r, eval=F}
rm(list=ls())
load(file = 'Section1.RData')
```



---
Back to course [home page](https://github.com/MayInstitute/MayInstitute2017/blob/master/Program3_Intro%20stat%20in%20R/README.md)
